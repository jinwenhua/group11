{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d2d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python libraries\n",
    "import pandas as pd                  # Use pandas.DataFrame to manipulate data\n",
    "import matplotlib.pyplot as plt      # Standard plotting library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn import preprocessing    # Data preprocessing\n",
    "\n",
    "# Model selection - split data, cv, model evaluation\n",
    "from sklearn.model_selection import train_test_split    # Split dataset into training and test sets\n",
    "from sklearn.model_selection import cross_val_score     # k-fold cross-validation\n",
    "from sklearn.model_selection import GridSearchCV        # search for best parameters\n",
    "from sklearn import metrics                             # metrics to evaluate the model performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix    # analyze prediction made by the classification model\n",
    "\n",
    "# Machine learning algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Feature extraction - Decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "# Ensemble learning methods\n",
    "from sklearn.ensemble import BaggingClassifier            # Bagging - (B)ootstrap (AGG)regat(ING)\n",
    "from sklearn.ensemble import AdaBoostClassifier           # Boosting - (ADA)ptive (BOOST)ing\n",
    "from sklearn.ensemble import VotingClassifier             # Voting\n",
    "\n",
    "# Itertools - here, used to generate combinations of base classifiers for voting\n",
    "import itertools\n",
    "# Silence all war\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0864bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train data set in dataframe from train_data.csv file\n",
    "df = pd.read_csv(\"winequality-white.csv\")\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1045af8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3655\n",
       "2    1060\n",
       "0     183\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(len(df)):\n",
    "    if df['quality'].iloc[i] == 3 or df['quality'].iloc[i] == 4  :\n",
    "        df['quality'].iloc[i] = 0\n",
    "    if  df['quality'].iloc[i] == 6 or df['quality'].iloc[i] == 5 :\n",
    "        df['quality'].iloc[i] = 1\n",
    "    if df['quality'].iloc[i] == 7 or df['quality'].iloc[i] == 8 or df['quality'].iloc[i] == 9 :\n",
    "        df['quality'].iloc[i] = 2\n",
    "df['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72adb92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  alcohol  \n",
       "0                 45.0                 170.0    1.001  3.0       0.45      8.8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indicate the target column\n",
    "target = df['quality']\n",
    "# Indicate the columns that will serve as features\n",
    "features = df.drop('quality', axis = 1)\n",
    "features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf0fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dbca196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17209696, -0.0817699 ,  0.2132802 ,  2.82134917, -0.035355  ,\n",
       "        0.56993158,  0.74456503,  2.33151201, -1.24692128, -0.34918426,\n",
       "       -1.39315246])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fcc0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function #1: train and evaluate model performance.\n",
    "# - The parameter `estimator` takes a list of classifier dictionary: {name, classifier}\n",
    "def train_and_evaluate(estimators, X_train, X_test, Y_train, Y_test):\n",
    "    # Nested function #1: Specify performance metric: only \"f1_macro\"\n",
    "    def get_scoring_metric():\n",
    "        return ['f1_macro']\n",
    "    \n",
    "    # Nested function #2: K-fold cross validation\n",
    "    def print_validation_performance(estimator, X_train, Y_train, name=None, cv=10):\n",
    "        for metric in get_scoring_metric():\n",
    "            scores = cross_val_score(estimator, X_train, Y_train, cv=cv, scoring=metric)\n",
    "            estimator_name = \"\"\n",
    "            \n",
    "            if name is not None:\n",
    "                estimator_name = \" {}\".format(name)\n",
    "                \n",
    "            print(\"{} (Validation{}) = \".format(metric, estimator_name), end=\"\")\n",
    "            print(\"{:.4f}\".format(scores.mean()))\n",
    "    \n",
    "    # Nested function #3: Training and testing\n",
    "    def print_test_performance(estimator, X_train, X_test, Y_train, Y_test, name=None):\n",
    "        estimator.fit(X_train, Y_train)\n",
    "        test_predict = estimator.predict(X_test)\n",
    "        dict_score = {}\n",
    "        # Get performance score for each metric\n",
    "        for metric in get_scoring_metric():\n",
    "            estimator_name = \"\"\n",
    "            score = 0.0\n",
    "            \n",
    "            if name is not None:\n",
    "                estimator_name = \" {}\".format(name) \n",
    "            \n",
    "            average = None\n",
    "            acc_flag = True\n",
    "            \n",
    "            if \"macro\" in metric:\n",
    "                average = \"macro\"\n",
    "                acc_flag = False\n",
    "            elif \"weighted\" in metric:\n",
    "                average = \"weighted\"\n",
    "                acc_flag = False\n",
    "            \n",
    "            print(\"{} (Test{}) = \".format(metric, estimator_name), end=\"\")\n",
    "            \n",
    "            # Currently only supports accuracy and f1_score.\n",
    "            if acc_flag:\n",
    "                score = metrics.accuracy_score(Y_test, test_predict)\n",
    "            else:\n",
    "                score = metrics.f1_score(Y_test, test_predict, average=average)\n",
    "            \n",
    "            print(\"{:.4f}\".format(score)) \n",
    "            dict_score[metric] = score\n",
    "        \n",
    "        print(confusion_matrix(Y_test, test_predict))         # Confusion matrix\n",
    "        print(classification_report(Y_test, test_predict))    # Classification report\n",
    "        \n",
    "        return dict_score\n",
    "    \n",
    "    dict_est_score = {}\n",
    "    \n",
    "    # Print validation and test performance for all classifiers in the list.\n",
    "    for key_est in estimators:\n",
    "        print_validation_performance(estimators[key_est], X_train, Y_train, name=key_est)\n",
    "        dict_est_score[key_est] = print_test_performance(estimators[key_est], \n",
    "                                                         X_train, X_test, Y_train, Y_test, \n",
    "                                                         name=key_est)\n",
    "        print()\n",
    "        \n",
    "    return dict_est_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df0774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b26158f6",
   "metadata": {},
   "source": [
    "# 3.Ensemble Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5979118",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_clf_default = {\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(), \n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"Linear SVM\": SVC(kernel='linear', max_iter=1500), \n",
    "    \"Polynomial SVM\": SVC(kernel='poly', max_iter=1500), \n",
    "    \"RBF SVM\": SVC(kernel='rbf', max_iter=1500), \n",
    "    \"Sigmoid SVM\": SVC(kernel='sigmoid', max_iter=1500),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17aab85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Decision Tree) = 0.5888\n",
      "f1_macro (Test Decision Tree) = 0.5960\n",
      "[[ 10  18   2]\n",
      " [ 33 597  93]\n",
      " [  1  65 161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.33      0.27        30\n",
      "           1       0.88      0.83      0.85       723\n",
      "           2       0.63      0.71      0.67       227\n",
      "\n",
      "    accuracy                           0.78       980\n",
      "   macro avg       0.58      0.62      0.60       980\n",
      "weighted avg       0.80      0.78      0.79       980\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Decision Tree': {'f1_macro': 0.5959901455268525}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify one classifier\n",
    "clf_index = 1\n",
    "\n",
    "estimator_name = list(dict_clf_default.keys())[clf_index]\n",
    "estimator = {estimator_name: dict_clf_default[estimator_name]}\n",
    "\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fde1d736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation K-Nearest Neighbors) = 0.5114\n",
      "f1_macro (Test K-Nearest Neighbors) = 0.5850\n",
      "[[  6  23   1]\n",
      " [  8 661  54]\n",
      " [  0 104 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.20      0.27        30\n",
      "           1       0.84      0.91      0.87       723\n",
      "           2       0.69      0.54      0.61       227\n",
      "\n",
      "    accuracy                           0.81       980\n",
      "   macro avg       0.65      0.55      0.59       980\n",
      "weighted avg       0.79      0.81      0.79       980\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.5888\n",
      "f1_macro (Test Decision Tree) = 0.5960\n",
      "[[ 10  18   2]\n",
      " [ 33 597  93]\n",
      " [  1  65 161]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.33      0.27        30\n",
      "           1       0.88      0.83      0.85       723\n",
      "           2       0.63      0.71      0.67       227\n",
      "\n",
      "    accuracy                           0.78       980\n",
      "   macro avg       0.58      0.62      0.60       980\n",
      "weighted avg       0.80      0.78      0.79       980\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Linear SVM) = 0.4068\n",
      "f1_macro (Test Linear SVM) = 0.4340\n",
      "[[  2  21   7]\n",
      " [ 13 498 212]\n",
      " [  1  90 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.07      0.09        30\n",
      "           1       0.82      0.69      0.75       723\n",
      "           2       0.38      0.60      0.47       227\n",
      "\n",
      "    accuracy                           0.65       980\n",
      "   macro avg       0.44      0.45      0.43       980\n",
      "weighted avg       0.70      0.65      0.66       980\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Polynomial SVM) = 0.4692\n",
      "f1_macro (Test Polynomial SVM) = 0.4842\n",
      "[[  4  24   2]\n",
      " [  5 680  38]\n",
      " [  0 162  65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.13      0.21        30\n",
      "           1       0.79      0.94      0.86       723\n",
      "           2       0.62      0.29      0.39       227\n",
      "\n",
      "    accuracy                           0.76       980\n",
      "   macro avg       0.62      0.45      0.48       980\n",
      "weighted avg       0.74      0.76      0.73       980\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation RBF SVM) = 0.4497\n",
      "f1_macro (Test RBF SVM) = 0.4735\n",
      "[[  1  29   0]\n",
      " [  0 698  25]\n",
      " [  0 147  80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06        30\n",
      "           1       0.80      0.97      0.87       723\n",
      "           2       0.76      0.35      0.48       227\n",
      "\n",
      "    accuracy                           0.79       980\n",
      "   macro avg       0.85      0.45      0.47       980\n",
      "weighted avg       0.80      0.79      0.76       980\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Sigmoid SVM) = 0.4185\n",
      "f1_macro (Test Sigmoid SVM) = 0.4450\n",
      "[[  5  24   1]\n",
      " [ 28 595 100]\n",
      " [  9 138  80]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.17      0.14        30\n",
      "           1       0.79      0.82      0.80       723\n",
      "           2       0.44      0.35      0.39       227\n",
      "\n",
      "    accuracy                           0.69       980\n",
      "   macro avg       0.45      0.45      0.45       980\n",
      "weighted avg       0.69      0.69      0.69       980\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Logistic Regression) = 0.4456\n",
      "f1_macro (Test Logistic Regression) = 0.4314\n",
      "[[  1  28   1]\n",
      " [  2 675  46]\n",
      " [  0 162  65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.03      0.06        30\n",
      "           1       0.78      0.93      0.85       723\n",
      "           2       0.58      0.29      0.38       227\n",
      "\n",
      "    accuracy                           0.76       980\n",
      "   macro avg       0.56      0.42      0.43       980\n",
      "weighted avg       0.72      0.76      0.72       980\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_0</th>\n",
       "      <th>classifier_1</th>\n",
       "      <th>classifier_2</th>\n",
       "      <th>classifier_3</th>\n",
       "      <th>classifier_4</th>\n",
       "      <th>classifier_5</th>\n",
       "      <th>classifier_6</th>\n",
       "      <th>test_performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.585017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.595990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.434019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.484193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.473528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.445033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>Polynomial SVM</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>Sigmoid SVM</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.431404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          classifier_0   classifier_1 classifier_2    classifier_3  \\\n",
       "0  K-Nearest Neighbors  Decision Tree   Linear SVM  Polynomial SVM   \n",
       "1  K-Nearest Neighbors  Decision Tree   Linear SVM  Polynomial SVM   \n",
       "2  K-Nearest Neighbors  Decision Tree   Linear SVM  Polynomial SVM   \n",
       "3  K-Nearest Neighbors  Decision Tree   Linear SVM  Polynomial SVM   \n",
       "4  K-Nearest Neighbors  Decision Tree   Linear SVM  Polynomial SVM   \n",
       "5  K-Nearest Neighbors  Decision Tree   Linear SVM  Polynomial SVM   \n",
       "6  K-Nearest Neighbors  Decision Tree   Linear SVM  Polynomial SVM   \n",
       "\n",
       "  classifier_4 classifier_5         classifier_6  test_performance  \n",
       "0      RBF SVM  Sigmoid SVM  Logistic Regression          0.585017  \n",
       "1      RBF SVM  Sigmoid SVM  Logistic Regression          0.595990  \n",
       "2      RBF SVM  Sigmoid SVM  Logistic Regression          0.434019  \n",
       "3      RBF SVM  Sigmoid SVM  Logistic Regression          0.484193  \n",
       "4      RBF SVM  Sigmoid SVM  Logistic Regression          0.473528  \n",
       "5      RBF SVM  Sigmoid SVM  Logistic Regression          0.445033  \n",
       "6      RBF SVM  Sigmoid SVM  Logistic Regression          0.431404  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Baseline - compare all classifiers\n",
    "list_clf = []\n",
    "list_score = []\n",
    "\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "# Generating results\n",
    "# ---\n",
    "# Iterate through all classifiers\n",
    "for clf in dict_clf_default:\n",
    "    estimator = { clf: dict_clf_default[clf] }\n",
    "    try:\n",
    "        score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    list_clf.append(clf)\n",
    "    list_score = list_score + list(score[clf].values())\n",
    "\n",
    "    \n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict(classifier=list_clf, test_performance=list_score)\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# # Save and export df_performance to CSV file (optional)\n",
    "# df_performance.to_csv(r'final_project_performance_default.csv', index = False, hea\n",
    "\n",
    "# Plotting\n",
    "# ---\n",
    "str_x_label = \"Model Test Performance ({} {})\".format(average_param.capitalize(), score_param.capitalize())\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(list_clf, list_score)\n",
    "\n",
    "plt.title(\"{} on Different Classifiers\".format(str_x_label), fontsize=(font_size + 4))\n",
    "plt.xlabel(str_x_label, fontsize=(font_size + 2))\n",
    "plt.ylabel(\"Classifiers\", fontsize=(font_size + 2))\n",
    "\n",
    "plt.show()\n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict()\n",
    "for i, base_clf in enumerate(list_clf):\n",
    "    clf_key = \"classifier_{}\".format(i)\n",
    "    data[clf_key] = base_clf\n",
    "\n",
    "data[\"test_performance\"] = list_score\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# Save and export df_performance to CSV file (optional)\n",
    "df_performance.to_csv(r'final_project_performance_baseline_{}clf.csv'.format(3), index = False, header = True)\n",
    "\n",
    "df_performance\n",
    "\n",
    "# # Save plot into PNG (optional) \n",
    "# plt.savefig(\"final_project_performance_default.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b1abda",
   "metadata": {},
   "source": [
    "# 3.1Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f68c3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation Bagging - Decision Tree) = 0.6274\n",
      "f1_macro (Test Bagging - Decision Tree) = 0.6428\n",
      "[[  6  24   0]\n",
      " [  6 684  33]\n",
      " [  0  76 151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29        30\n",
      "           1       0.87      0.95      0.91       723\n",
      "           2       0.82      0.67      0.73       227\n",
      "\n",
      "    accuracy                           0.86       980\n",
      "   macro avg       0.73      0.60      0.64       980\n",
      "weighted avg       0.85      0.86      0.85       980\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bagging - Decision Tree': {'f1_macro': 0.6427570807132851}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify classifier\n",
    "clf_index = 1    # Accepts value from 0 - 6\n",
    "\n",
    "# Define parameter values for BaggingClassifier object\n",
    "base = list(dict_clf_default.values())[clf_index]\n",
    "bagging_param = dict(base_estimator=base,\n",
    "                     n_estimators=100,    # create 100 different models using the same `base_estimator`\n",
    "                     random_state=0)\n",
    "\n",
    "# Define BaggingClassifier object\n",
    "model_bagging = BaggingClassifier(**bagging_param)\n",
    "\n",
    "estimator_name = \"Bagging - {}\".format(list(dict_clf_default.keys())[clf_index])\n",
    "estimator = {estimator_name: model_bagging}\n",
    "\n",
    "# Train and evaluate the performance of the bagging classifier\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9991c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro (Validation K-Nearest Neighbors) = 0.5153\n",
      "f1_macro (Test K-Nearest Neighbors) = 0.5778\n",
      "[[  5  24   1]\n",
      " [  3 661  59]\n",
      " [  0 105 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.17      0.26        30\n",
      "           1       0.84      0.91      0.87       723\n",
      "           2       0.67      0.54      0.60       227\n",
      "\n",
      "    accuracy                           0.80       980\n",
      "   macro avg       0.71      0.54      0.58       980\n",
      "weighted avg       0.79      0.80      0.79       980\n",
      "\n",
      "\n",
      "\n",
      "f1_macro (Validation Decision Tree) = 0.6274\n",
      "f1_macro (Test Decision Tree) = 0.6428\n",
      "[[  6  24   0]\n",
      " [  6 684  33]\n",
      " [  0  76 151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29        30\n",
      "           1       0.87      0.95      0.91       723\n",
      "           2       0.82      0.67      0.73       227\n",
      "\n",
      "    accuracy                           0.86       980\n",
      "   macro avg       0.73      0.60      0.64       980\n",
      "weighted avg       0.85      0.86      0.85       980\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bagging - compare all classifiers\n",
    "list_clf = []\n",
    "list_score = []\n",
    "\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "bagging_param = dict(n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "# Generate results\n",
    "# ---\n",
    "# Iterate through all classifiers\n",
    "for i, clf in enumerate(dict_clf_default):\n",
    "    base = dict_clf_default[clf]\n",
    "    \n",
    "    params = bagging_param.copy()\n",
    "    params[\"base_estimator\"] = base\n",
    "\n",
    "    model_bagging = BaggingClassifier(**params)\n",
    "    \n",
    "    estimator = { clf: model_bagging }\n",
    "    \n",
    "    try:\n",
    "        score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    list_clf.append(clf)\n",
    "    list_score = list_score + list(score[clf].values())\n",
    "    # Create data frame\n",
    "# ---\n",
    "data = dict(classifier=list_clf, test_performance=list_score)\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# # Save and export df_performance to CSV file (optional)\n",
    "# df_performance.to_csv(r'final_project_performance_bagging.csv', index = False, header = True)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# ---\n",
    "str_x_label = \"Model Test Performance ({} {})\".format(average_param.capitalize(), score_param.capitalize())\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(list_clf, list_score)\n",
    "\n",
    "plt.title(\"Bagging: {} on Different Base Classifiers\".format(str_x_label), fontsize=(font_size + 4))\n",
    "plt.xlabel(str_x_label, fontsize=(font_size + 2))\n",
    "plt.ylabel(\"Base Classifiers\", fontsize=(font_size + 2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict()\n",
    "for i, base_clf in enumerate(list_clf):\n",
    "    clf_key = \"classifier_{}\".format(i)\n",
    "    data[clf_key] = base_clf\n",
    "\n",
    "data[\"test_performance\"] = list_score\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# Save and export df_performance to CSV file (optional)\n",
    "df_performance.to_csv(r'final_project_performance_bagging_{}clf.csv'.format(3), index = False, header = True)\n",
    "\n",
    "df_performance\n",
    "# # Save plot into PNG (optional) \n",
    "# plt.savefig(\"final_project_performance_bagging.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccef7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "features[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9238698",
   "metadata": {},
   "source": [
    "# 3.2 boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = [print(\"Index: {} - {}\".format(i, clf)) for i, clf in enumerate(dict_clf_default)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed53d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify one classifier\n",
    "clf_index = 1    # Accepts value from 0 - 6\n",
    "\n",
    "# Define parameter values for AdaBoostClassifier object\n",
    "base = list(dict_clf_default.values())[clf_index]\n",
    "boosting_param = dict(base_estimator=base,\n",
    "                     n_estimators=100,\n",
    "                     random_state=0)\n",
    "\n",
    "# Define AdaBoostClassifier object\n",
    "model_boosting = AdaBoostClassifier(**boosting_param)\n",
    "\n",
    "estimator_name = \"Boosting - {}\".format(list(dict_clf_default.keys())[clf_index])\n",
    "estimator = {estimator_name: model_boosting}\n",
    "\n",
    "# Train and evaluate the performance of the AdaBoost classifier\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Boosting \n",
    "clf_index = 2    # Accepts value from 0 - 6\n",
    "\n",
    "# Define parameter values for AdaBoostClassifier object\n",
    "base = list(dict_clf_default.values())[clf_index]\n",
    "boosting_param = dict(base_estimator=base,\n",
    "                     n_estimators=100,\n",
    "                     algorithm='SAMME',random_state=0)\n",
    "\n",
    "# Define AdaBoostClassifier object\n",
    "model_boosting = AdaBoostClassifier(**boosting_param)\n",
    "#model_boosting = AdaBoostClassifier((svm.SVC(probability=True,kernel='linear'),n_estimators=50,learning_rate=1.0,algorithm='SAMME')\n",
    "\n",
    "estimator_name = \"Boosting - {}\".format(list(dict_clf_default.keys())[clf_index])\n",
    "estimator = {estimator_name: model_boosting}\n",
    "\n",
    "# Train and evaluate the performance of the AdaBoost classifier\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e947dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all classifiers\n",
    "list_clf = []\n",
    "list_score = []\n",
    "\n",
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "feature_train = x_train\n",
    "feature_test = x_test\n",
    "\n",
    "# Initialize parameter values of boosting classifier\n",
    "boosting_param = dict(n_estimators=100,random_state=0)\n",
    "\n",
    "# Loop through all classifiers\n",
    "# ---\n",
    "for i, clf in enumerate(dict_clf_default):\n",
    "    print(\"- {}\".format(clf))\n",
    "    base = dict_clf_default[clf]\n",
    "    \n",
    "    if i<1:\n",
    "        params = boosting_param.copy()\n",
    "    else:\n",
    "        params = dict(n_estimators=100,algorithm='SAMME',random_state=0)\n",
    "    \n",
    "    params[\"base_estimator\"] = base\n",
    "    \n",
    "    \n",
    "    estimator = { clf: model_boosting }\n",
    "    \n",
    "    try:\n",
    "        score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    list_clf.append(clf)\n",
    "    list_score = list_score + list(score[clf].values())\n",
    "    # Create data frame\n",
    "# ---\n",
    "data = dict(classifier=list_clf, test_performance=list_score)\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# # Save and export df_performance to CSV file\n",
    "# df_performance.to_csv(r'final_project_performance_boosting.csv', index = False, header = True)\n",
    "\n",
    "# Plotting\n",
    "# ---\n",
    "str_x_label = \"Model Test Performance ({} {})\".format(average_param.capitalize(), score_param.capitalize())\n",
    "font_size = 12\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.barh(list_clf, list_score)\n",
    "\n",
    "plt.title(\"Boosting: {} on Different Base Classifiers\".format(str_x_label), fontsize=(font_size + 4))\n",
    "plt.xlabel(str_x_label, fontsize=(font_size + 2))\n",
    "plt.ylabel(\"Base Classifiers\", fontsize=(font_size + 2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "##Save plot into PNG (optional) \n",
    "##plt.savefig(\"final_project_performance_boosting.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict()\n",
    "for i, base_clf in enumerate(list_clf):\n",
    "    clf_key = \"classifier_{}\".format(i)\n",
    "    data[clf_key] = base_clf\n",
    "\n",
    "data[\"test_performance\"] = list_score\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# Save and export df_performance to CSV file (optional)\n",
    "df_performance.to_csv(r'final_project_performance_boosting_{}clf.csv'.format(3), index = False, header = True)\n",
    "\n",
    "df_performance\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d6a676",
   "metadata": {},
   "source": [
    "# 3.3 Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd5316",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "# specify number of base classifiers\n",
    "num_base_clf = 3                                # Accepts values from 2 - 4 (number of base classifiers)\n",
    "list_clf = [[] for i in range(num_base_clf)]    # 2-dimensional list, to store list of classifiers in\n",
    "                                                # each voting classifier\n",
    "list_score = []\n",
    "\n",
    "# Generate all possible combinations of base classifiers with # of classifiers = num_base_clf\n",
    "# ---\n",
    "# For example: if num_base_clf = 3, \n",
    "# [A, B, C, D] -> [A, B, C], [A, B, D], [A, C, D] and [B, C, D]\n",
    "combinations_base_clf = itertools.combinations(dict_clf_default, num_base_clf)\n",
    "\n",
    "# Iterate through all generated lists\n",
    "for comb in combinations_base_clf:\n",
    "    list_base_clf = []\n",
    "    \n",
    "    # Return number of SVM classifiers in a list\n",
    "    count_svm = sum(\"SVM\" in clf for clf in comb)    \n",
    "    \n",
    "    # At most one SVM classifier in the list.\n",
    "    # - skip all the lists with >1 classifiers - speed up iteration\n",
    "    # - ensure variation in machine learning algorithms in the voting classifier\n",
    "    if count_svm <= 1:\n",
    "        for i, clf in enumerate(comb):\n",
    "            list_base_clf.append((clf, dict_clf_default[clf]))\n",
    "            list_clf[i].append(clf)\n",
    "    \n",
    "        print(comb)\n",
    "        print(\"---\")\n",
    "        \n",
    "        try:\n",
    "            model_voting = VotingClassifier(estimators=list_base_clf)\n",
    "            estimator_name = \"Voting Classifier\"\n",
    "            estimator = { estimator_name : model_voting }\n",
    "            score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "            \n",
    "            list_score = list_score + list(score[estimator_name].values())\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_class_name = e.__class__.__name__\n",
    "            print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "            continue\n",
    "        \n",
    "        print()\n",
    "\n",
    "        \n",
    "# Create data frame\n",
    "# ---\n",
    "data = dict()\n",
    "for i, base_clf in enumerate(list_clf):\n",
    "    clf_key = \"classifier_{}\".format(i)\n",
    "    data[clf_key] = base_clf\n",
    "\n",
    "data[\"test_performance\"] = list_score\n",
    "df_performance = pd.DataFrame(data=data)\n",
    "\n",
    "# Save and export df_performance to CSV file (optional)\n",
    "df_performance.to_csv(r'final_project_performance_voting_{}clf.csv'.format(3), index = False, header = True)\n",
    "\n",
    "df_performance\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting 继承学习\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_index = 1    # Accepts value from 0 - 6\n",
    "\n",
    "log = LogisticRegression()\n",
    "rnd = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "\n",
    "# Define VotingClassifier object\n",
    "model_boosting = VotingClassifier(estimators=[('lr',log), ('rf',rnd), ('svm',svm)],voting='hard')\n",
    "\n",
    "estimator_name = \"Voting - {}\".format(list(dict_clf_default.keys())[clf_index])\n",
    "estimator = {estimator_name: model_boosting}\n",
    "\n",
    "# Train and evaluate the performance of the Voting classifier\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1ce41a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf71628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad454b",
   "metadata": {},
   "source": [
    "# 3.4 stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c2f3c",
   "metadata": {},
   "source": [
    "# Stacking-single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a27950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define StackingClassifier object\n",
    "estimators = [ ('rf', RandomForestClassifier(random_state=42)),\n",
    "             ('nk',KNeighborsClassifier())]\n",
    "\n",
    "model_boosting = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "estimator_name = \"Stacking - {}\".format(list(dict_clf_default.keys())[clf_index])\n",
    "estimator = {estimator_name: model_boosting}\n",
    "\n",
    "# Train and evaluate the performance of the Voting classifier\n",
    "train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c440eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_clf_default = {\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(), \n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"Linear SVM\": SVC(kernel='linear', max_iter=1500), \n",
    "    \"Polynomial SVM\": SVC(kernel='poly', max_iter=1500), \n",
    "    \"RBF SVM\": SVC(kernel='rbf', max_iter=1500), \n",
    "    \"Sigmoid SVM\": SVC(kernel='sigmoid', max_iter=1500),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97767ae2",
   "metadata": {},
   "source": [
    "# Stacking- three random group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_param = \"f1_score\"\n",
    "average_param = \"macro\"\n",
    "\n",
    "# specify number of base classifiers\n",
    "num_base_clf = 3                                # Accepts values from 2 - 4 (number of base classifiers)\n",
    "list_clf = [[] for i in range(num_base_clf)]    # 2-dimensional list, to store list of classifiers in\n",
    "                                                # each voting classifier\n",
    "list_score = []\n",
    "\n",
    "# For example: if num_base_clf = 3, \n",
    "# [A, B, C, D] -> [A, B, C], [A, B, D], [A, C, D] and [B, C, D]\n",
    "combinations_base_clf = itertools.combinations(dict_clf_default, num_base_clf)\n",
    "\n",
    "nameList=[]\n",
    "listAll=[]\n",
    "for comb in combinations_base_clf:\n",
    "    nameList.append(comb)\n",
    "    list1=[]\n",
    "    for name in comb:\n",
    "       \n",
    "        list1.append((name, dict_clf_default.get(name)))\n",
    "    listAll.append(list1)\n",
    "\n",
    "# Iterate through all generated lists\n",
    "i=0\n",
    "for comb in listAll:\n",
    "    print(nameList[i])\n",
    "    print(\"---\")\n",
    "    i+=1\n",
    "    try:\n",
    "        model_voting = StackingClassifier(estimators=comb, final_estimator=LogisticRegression())\n",
    "        estimator_name = \"Stacking Classifier\"\n",
    "        estimator = { estimator_name : model_voting }\n",
    "        score = train_and_evaluate(estimator, x_train, x_test, y_train, y_test)\n",
    "\n",
    "        list_score = list_score + list(score[estimator_name].values())\n",
    "\n",
    "    except Exception as e:\n",
    "        error_class_name = e.__class__.__name__\n",
    "        print(\"{}: {}\\n\".format(error_class_name, e))\n",
    "        continue\n",
    "\n",
    "    print(\"------------------------------------------------------------------------------\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame\n",
    "# ---\n",
    "for comb in nameList:\n",
    "    for i, clf in enumerate(comb):\n",
    "                list_base_clf.append((clf, dict_clf_default[clf]))\n",
    "                list_clf[i].append(clf)\n",
    "\n",
    "            \n",
    "data = dict()\n",
    "for i, base_clf in enumerate(list_clf):\n",
    "    clf_key = \"classifier_{}\".format(i)\n",
    "    data[clf_key] = base_clf\n",
    "\n",
    "data[\"test_performance\"] = list_score\n",
    "df_performance1 = pd.DataFrame(data=data)\n",
    "\n",
    "# Save and export df_performance to CSV file (optional)\n",
    "df_performance1.to_csv(r'final_project_performance_stacking_{}clf.csv'.format(3), index = False, header = True)\n",
    "\n",
    "df_performance1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062c02a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ddd74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad34a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
